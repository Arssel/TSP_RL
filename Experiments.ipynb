{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Improvement Heuristics for Solving the Travelling Salesman Problem (13)\n",
    "\n",
    "Задача состояла в воспроизведении результатов статьи https://arxiv.org/pdf/1912.05784v1.pdf. Статья посвящена улучшению имеющихся решений проблемы коммивояжера с евклидовыми расстояниями между точками с использованием обучения с подкреплением. Были написаны среда и модель для проведения экспериментов. Был написан модуль обучения, но в проведенных экспериментах не получилось достичь точности рассматриваемых авторами solver'ов. Сравнение проивзодилось с API от компании Google OR-Tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постановка задачи\n",
    "Опишем среду, действия и награды:\n",
    "1. Множество состояний среды - множество всевозможных перестановок $n$ точек. \n",
    "2. Действия - обращения порядка следования точек в заданной перестановке между двумя выбранными точками.\n",
    "3. Награда - в случае уменьшения суммарного расстояния между точками - разница между суммарным расстоянием до изменения и после, в случае увеличения/не изменения - ноль. \n",
    "\n",
    "В качестве алгоритма обучения использовался Actor-Critic с forward-view равным $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.architectures import Actor, Critic\n",
    "from src.environment import TSPEnv\n",
    "from src.train import train, train_one_batch\n",
    "from src.heuristics import compute_distance, insert_heuristic, nearest_neighbour\n",
    "from src.utils import sample_nodes\n",
    "from src.presentation import test_metric_by_graph_size, compute_actor_distance\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import timeit\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использованные гиперпараметры\n",
    "\n",
    "Размер графа - 20 точек. Для каждой эпохи генерируется 10240 графа (batch_size=256). Всего 200 эпох. Learning rate для оптимизатора Adam - $10^{-4}$. Дисконтирующий множетель наград - 0.99. Число шагов в farward-view - 4. Длительность улучшения решения - 200 шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "TSP_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor().to(device)\n",
    "critic = Critic(batch_size=batch_size, n=TSP_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_batch(actor, critic, device, batch_size=batch_size, epochs=1, TSP_size=TSP_size, batch_times=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(actor, critic, device, batch_size=batch_size, epochs=200, TSP_size=TSP_size, batch_times=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(actor, './models/actor_20_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(critic, './models/critic_20_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование различий в метриках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(\n",
       "  (linear_embedding): LinearEmbedding(\n",
       "    (projection): Linear(in_features=2, out_features=128, bias=True)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (s_att): AttentionLayer(\n",
       "          (linear_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (s_att): AttentionLayer(\n",
       "          (linear_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (s_att): AttentionLayer(\n",
       "          (linear_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): DecoderActor(\n",
       "    (linear_graph): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear_nodes): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor = torch.load('./models/actor_50_new')\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('distances.pkl', 'rb')\n",
    "\n",
    "distances = pickle.load(f)\n",
    "distances = np.array(distances)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('distances_new.pkl', 'rb')\n",
    "\n",
    "distances_new = pickle.load(f)\n",
    "distances_new = np.array(distances_new)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dataset.pkl', 'rb')\n",
    "\n",
    "dataset = pickle.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "TSP_size = 50\n",
    "env = TSPEnv(n=TSP_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_actor_distance(actor, window=1000, device='cpu', dots=None, distances=None):\n",
    "    bsz, n, _ = dots.shape\n",
    "    env = TSPEnv(n=n, batch_size=bsz)\n",
    "    env.reset()\n",
    "    env._dots = dots\n",
    "    env._distances = distances\n",
    "    observations = env.get_observations()\n",
    "    dots = torch.Tensor(dots).to(device)\n",
    "    permuted_dots = env.permute_dots(observations, dots)\n",
    "    for t in np.arange(window):\n",
    "        _, actions = sample_nodes(actor(permuted_dots))\n",
    "        observations, _, _ = env.step(actions)\n",
    "        permuted_dots = env.permute_dots(observations, dots)\n",
    "    return env.get_best_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = [1, 1.1, 1.25, 1.4, 1.5, 1.6, 1.75, 1.9, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█████████▏                                                                         | 1/9 [04:32<36:17, 272.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██████████████████▍                                                                | 2/9 [09:02<31:40, 271.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███████████████████████████▋                                                       | 3/9 [13:25<26:53, 268.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████████████████████████▉                                              | 4/9 [17:43<22:09, 265.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|██████████████████████████████████████████████                                     | 5/9 [22:03<17:36, 264.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 6/9 [26:24<13:09, 263.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|████████████████████████████████████████████████████████████████▌                  | 7/9 [30:53<08:49, 264.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████████████████████████████████████████████▊         | 8/9 [35:20<04:25, 265.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 9/9 [39:49<00:00, 265.52s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model_results = np.zeros((len(p_list), 2000//batch_size))\n",
    "for p in tqdm(range(len(p_list))):\n",
    "    for b in range(2000//batch_size):\n",
    "        model_results[p, b] = compute_actor_distance(actor,\\\n",
    "                               window=1000,\\\n",
    "                               device=device,\\\n",
    "                               dots=dataset[b*batch_size:b*batch_size+batch_size],\\\n",
    "                               distances=distances[p, b*batch_size:b*batch_size+batch_size]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█████████▏                                                                         | 1/9 [04:06<32:50, 246.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██████████████████▍                                                                | 2/9 [08:21<29:02, 248.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███████████████████████████▋                                                       | 3/9 [12:38<25:08, 251.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████████████████████████▉                                              | 4/9 [17:03<21:16, 255.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|██████████████████████████████████████████████                                     | 5/9 [21:16<16:59, 254.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 6/9 [25:28<12:42, 254.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4f7e658f0de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                \u001b[0mdots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                distances=distances_new[p, b*batch_size:b*batch_size+batch_size]).mean()\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "model_results_new = np.zeros((len(p_list), 2000//batch_size))\n",
    "for p in tqdm(range(len(p_list))):\n",
    "    for b in range(2000//batch_size):\n",
    "        model_results_new[p, b] = compute_actor_distance(actor,\\\n",
    "                               window=1000,\\\n",
    "                               device=device,\\\n",
    "                               dots=dataset[b*batch_size:b*batch_size+batch_size],\\\n",
    "                               distances=distances_new[p, b*batch_size:b*batch_size+batch_size]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_2 = np.array([model_results.mean(axis=1)[0],\n",
    "                            model_results_new.mean(axis=1)[0],\n",
    "                            model_results_new.mean(axis=1)[1],\n",
    "                            model_results_new.mean(axis=1)[2],\n",
    "                            model_results.mean(axis=1)[1],\n",
    "                            model_results_new.mean(axis=1)[3],\n",
    "                            model_results_new.mean(axis=1)[4],\n",
    "                            model_results_new.mean(axis=1)[5],\n",
    "                            model_results.mean(axis=1)[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortools_results = pd.read_csv('TOURS_RES+ORTOOLS.CSV', sep=';').to_numpy()[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortools_results_new = pd.read_csv('TOURS_RES+ORTOOLS_new.CSV', sep=';').to_numpy()[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortools_results_2 = np.array([ortools_results.mean(axis=1)[0],\n",
    "                            ortools_results_new.mean(axis=1)[0],\n",
    "                            ortools_results_new.mean(axis=1)[1],\n",
    "                            ortools_results_new.mean(axis=1)[2],\n",
    "                            ortools_results.mean(axis=1)[1],\n",
    "                            ortools_results_new.mean(axis=1)[3],\n",
    "                            ortools_results_new.mean(axis=1)[4],\n",
    "                            ortools_results_new.mean(axis=1)[5],\n",
    "                            ortools_results.mean(axis=1)[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "pd.Series(1 - ortools_results_2/model_results_2, index=p_list).plot.bar()\n",
    "plt.xlabel('p', fontsize=16)\n",
    "plt.ylabel('gap', fontsize=16)\n",
    "plt.title('Gap between model and OR-tools for different metric')\n",
    "plt.savefig('L2I_gap.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замеры времени (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actor = torch.load('./models/actor_20_new')\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "batch_size = 256\n",
    "env = TSPEnv(n=n, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1000 шагов улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "env.reset(ret=False)\n",
    "actor_distance_1000 = compute_actor_distance(actor, env, 1000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 1000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "356.41708169999765/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3000 шагов улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "env.reset(ret=False)\n",
    "actor_distance_3000 = compute_actor_distance(actor, env, 3000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 3000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1077.4684396000084/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5000 шагов улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "env.reset(ret=False)\n",
    "actor_distance_5000 = compute_actor_distance(actor, env, 5000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 5000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1763/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1000 steps:', actor_distance_1000.mean())\n",
    "print('3000 steps:', actor_distance_3000.mean())\n",
    "print('5000 steps:', actor_distance_5000.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = env.get_dots()\n",
    "distances = env.get_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_limit = 17.8/batch_size\n",
    "or_1000_distances = []\n",
    "for i in range(batch_size):\n",
    "    or_1000_distances.append(compute_distance(distances[i], time_limit=time_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_limit = 53.8/batch_size\n",
    "or_3000_distances = []\n",
    "for i in range(batch_size):\n",
    "    or_3000_distances.append(compute_distance(distances[i], time_limit=time_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_limit = 88.15/batch_size\n",
    "or_3000_distances = []\n",
    "for i in range(batch_size):\n",
    "    or_3000_distances.append(compute_distance(distances[i], time_limit=time_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(or_1000_distances))\n",
    "print(np.mean(or_3000_distances))\n",
    "print(np.mean(or_5000_distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замеры времени (50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.load('./models/actor_50_new')\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "batch_size = 256\n",
    "env = TSPEnv(n=n, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1000 шагов улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "env.reset(ret=False)\n",
    "actor_distance_1000 = compute_actor_distance(actor, env, 1000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 1000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "707.4920411/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3000 шагов улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "env.reset(ret=False)\n",
    "actor_distance_3000 = compute_actor_distance(actor, env, 3000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 3000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2151.0882115/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5000 шагов улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "env.reset(ret=False)\n",
    "actor_distance_5000 = compute_actor_distance(actor, env, 5000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 5000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3547.4055358000005/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1000 steps:', actor_distance_1000.mean())\n",
    "print('3000 steps:', actor_distance_3000.mean())\n",
    "print('5000 steps:', actor_distance_5000.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = env.get_dots()\n",
    "distances = env.get_distances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_limit = 35.3/batch_size\n",
    "or_1000_distances = []\n",
    "for i in range(batch_size):\n",
    "    or_1000_distances.append(compute_distance(distances[i], time_limit=time_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_limit = 107/batch_size\n",
    "or_3000_distances = []\n",
    "for i in range(batch_size):\n",
    "    or_3000_distances.append(compute_distance(distances[i], time_limit=time_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_limit = 177/batch_size\n",
    "or_5000_distances = []\n",
    "for i in range(batch_size):\n",
    "    or_5000_distances.append(compute_distance(distances[i], time_limit=time_limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(or_1000_distances))\n",
    "print(np.mean(or_3000_distances))\n",
    "print(np.mean(or_5000_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "batch_size = 1\n",
    "env = TSPEnv(n=n, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.load('./models/actor_20_new')\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 1000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 3000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 5000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "batch_size = 1\n",
    "env = TSPEnv(n=n, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.load('./models/actor_50_new')\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 1000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 3000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(lambda: compute_actor_distance(actor, env, 5000, 'cuda'), number=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение на новом графе (50)\n",
    "\n",
    "Случайно инициализированный граф, на котором в течение 5000 шагов производится улучшение случайного начального."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.load('./models/actor_50_new')\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_space = np.arange(41, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_41_59 = test_metric_by_graph_size(actor, n_space, number_of_graphs=256, window=5000, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_41_59).to_csv('results_41_59.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение на новом графе (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.load('./models/actor_20_new')\n",
    "actor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_space = np.arange(11, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_11_29 = test_metric_by_graph_size(actor, n_space, number_of_graphs=256, window=5000, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_11_29).to_csv('results_11_29.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in np.arange(20, 90, 10):\n",
    "    env = TSPEnv(n=n, batch_size=256)\n",
    "    env.save_graph(\"dataset_\"+str(n)+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Графики обощения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50 = pd.read_csv('./results/results_50.csv', index_col=0)\n",
    "df_20 = pd.read_csv('./results/results_20.csv', index_col=0)\n",
    "df_10_30 = pd.read_csv('./results/results_11_29.csv', index_col=0)\n",
    "df_40_60 = pd.read_csv('./results/results_41_59.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['nearest_neighbour', 'closest_heuristic', 'farthest_heuristic', 'or-tools', 'model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_50 = np.arange(20, 90, 10)\n",
    "index_10_30 = np.arange(11, 30)\n",
    "index_40_60 = np.arange(41, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50.columns = columns\n",
    "df_50.index = index_50\n",
    "df_20.columns = columns\n",
    "df_20.index = index_50\n",
    "df_10_30.columns = columns\n",
    "df_10_30.index = index_10_30\n",
    "df_40_60.columns = columns\n",
    "df_40_60.index = index_40_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(df_10_30)\n",
    "plt.title('TSP20 for 11-29')\n",
    "plt.legend(columns)\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('Average found distance', fontsize=20)\n",
    "plt.savefig('./results/TSP20 for 11-29.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(df_20)\n",
    "plt.title('TSP20 for 20-80')\n",
    "plt.legend(columns)\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('Average found distance', fontsize=20)\n",
    "plt.savefig('./results/TSP20 for 20-80.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(df_50)\n",
    "plt.title('TSP50 for 20-80')\n",
    "plt.legend(columns)\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('Average found distance', fontsize=20)\n",
    "plt.savefig('./results/TSP50 for 20-80.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(df_40_60)\n",
    "plt.title('TSP50 for 41-59')\n",
    "plt.legend(columns)\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('Average found distance', fontsize=20)\n",
    "plt.savefig('./results/TSP50 for 41-59.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot((df_10_30['model'] - df_10_30['or-tools'])/df_10_30['or-tools']*100)\n",
    "plt.title('TSP20 GAP for 11-29')\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('%', fontsize=20)\n",
    "plt.legend(['gap between model and OR-tools'])\n",
    "#plt.savefig('./results/TSP20 GAP for 11-29.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot((df_20['model'] - df_20['or-tools'])/df_20['or-tools']*100)\n",
    "plt.title('TSP20 GAP for 20-80')\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('%', fontsize=20)\n",
    "plt.legend(['gap between model and OR-tools'])\n",
    "plt.savefig('./results/TSP20 GAP for 20-80.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot((df_50['model'] - df_50['or-tools'])/df_50['or-tools']*100)\n",
    "plt.title('TSP50 GAP for 20-80')\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('%', fontsize=20)\n",
    "plt.legend(['gap between model and OR-tools'])\n",
    "plt.savefig('./results/TSP50 GAP for 20-80.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot((df_40_60['model'] - df_40_60['or-tools'])/df_40_60['or-tools']*100)\n",
    "plt.title('TSP50 GAP for 41-59')\n",
    "plt.grid()\n",
    "plt.xlabel('N - graph size', fontsize=20)\n",
    "plt.ylabel('%', fontsize=20)\n",
    "plt.legend(['gap between model and OR-tools'])\n",
    "plt.savefig('./results/TSP50 GAP for 41-59.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анимация простейших эвристик\n",
    "Для графов размера 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.heuristics import insert_heuristic, nearest_neighbour\n",
    "from src.presentation import get_gif_animation_heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "env = TSPEnv(n=n, batch_size=1)\n",
    "dots = env.get_dots()\n",
    "distances = env.get_distances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эвристики ближайшей и удаленнейшей вставки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаленнейшая вставка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, seq, nodes = insert_heuristic(distances)\n",
    "dots_seq = [dots[:, seq[i],:].squeeze() for i in range(len(seq))]\n",
    "one_dot_seq = [dots[:, nodes[i], :].squeeze() for i in range(len(dots_seq[0])-1, len(nodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gif_animation_heuristics('./results/remote_gif_20.gif', dots_seq, one_dot_seq, interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ближайшая вставка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, seq, nodes = insert_heuristic(distances, insert_type='close')\n",
    "dots_seq = [dots[:, seq[i],:].squeeze() for i in range(len(seq))]\n",
    "one_dot_seq = [dots[:, nodes[i], :].squeeze() for i in range(len(dots_seq[0])-1, len(nodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gif_animation_heuristics('./results/close_gif_20.gif', dots_seq, one_dot_seq, interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эвристика ближайшего соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, seq, nodes = nearest_neighbour(distances)\n",
    "dots_seq = [dots[:, seq[i],:].squeeze() for i in range(len(seq))]\n",
    "one_dot_seq = [dots[:, nodes[i], :].squeeze() for i in range(len(dots_seq[0])-1, len(nodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_gif_animation_heuristics('./results/nearest_neighbour_20.gif', dots_seq, one_dot_seq, interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
